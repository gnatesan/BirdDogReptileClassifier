{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0GIM4yulcT7T"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "# general\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "\n",
        "\n",
        "# OOD Detection\n",
        "!pip install pytorch-ood\n",
        "\n",
        "try:\n",
        "  import timm\n",
        "except:\n",
        "  !pip install timm\n",
        "  import timm\n",
        "\n",
        "try:\n",
        "  import cleanlab\n",
        "except:\n",
        "  !pip install cleanlab\n",
        "\n",
        "## Ensemble-Specific\n",
        "!pip install Typing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "BfPMUFRWXryt",
        "outputId": "1692bf2b-11f3-40d8-ba94-7d60d3986ea5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ood in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Collecting torch==1.10.0\n",
            "  Using cached torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ood) (1.7.3)\n",
            "Collecting torchvision==0.11.1\n",
            "  Using cached torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (from pytorch-ood) (0.11.0)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.3->pytorch-ood) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->pytorch-ood) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1->pytorch-ood) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->pytorch-ood) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->pytorch-ood) (3.0.7)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0\n",
            "    Uninstalling torch-1.12.0:\n",
            "      Successfully uninstalled torch-1.12.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0\n",
            "    Uninstalling torchvision-0.13.0:\n",
            "      Successfully uninstalled torchvision-0.13.0\n",
            "Successfully installed torch-1.10.0 torchvision-0.11.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Typing in /usr/local/lib/python3.7/dist-packages (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogg-VdAXXhr7"
      },
      "outputs": [],
      "source": [
        "#@title Packages\n",
        "\n",
        "## General\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "## Data Analysis \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## Torch Specific\n",
        "# !pip install torchvision\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "## OOD Specific\n",
        "# cleanlab\n",
        "import cleanlab\n",
        "from cleanlab.outlier import OutOfDistribution\n",
        "from cleanlab.rank import find_top_issues\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuWIvxryYwxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8bOe4fcYK5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "TTUKUwPxX3O9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b1d9650-0504-44ce-8692-1e55337e27d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-WcJCw_xFhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BbvnS1w-xjC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision"
      ],
      "metadata": {
        "id": "zsJel_ukZeW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Data & Format Accordingly\n",
        "\n",
        "\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "\n",
        "\n",
        "train_dog = train_path + '/dog'\n",
        "train_bird = train_path + '/bird'\n",
        "train_rep = train_path + '/reptile' \n",
        "\n",
        "test_dog = test_path + '/dog'\n",
        "test_bird = test_path + '/bird'\n",
        "test_rep = test_path + '/reptile' \n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.ResNet50_Weights.DEFAULT.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "\n",
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "\n",
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_path,\n",
        "                                                                               test_dir=test_path,\n",
        "                                                                               transform=auto_transforms, # perform same data transforms on our own data as the pretrained model\n",
        "                                                                               batch_size = batch_size) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW6UKoqdYaZo",
        "outputId": "3559d825-4e0a-423d-cf33-a21ef9abd6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f978feb53d0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f979a63c250>,\n",
              " ['bird', 'dog', 'reptile'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-XZL1kGNV3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfUtDmpillog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Model"
      ],
      "metadata": {
        "id": "Xg-RDO4iXtOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helper functions"
      ],
      "metadata": {
        "id": "0GIM4yulcT7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model: torch.nn.Module, \n",
        "              dataloader: torch.utils.data.DataLoader, \n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "    a forward pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "\n",
        "    (0.0223, 0.8985)\n",
        "    \"\"\"\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch \n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "  \n"
      ],
      "metadata": {
        "id": "cnfwm8uucR5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Instantiate and test model"
      ],
      "metadata": {
        "id": "61b5TW2ydKpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModelTwo(nn.Module):   \n",
        "  '''\n",
        "  ensemble class will take two models this time and use their input to classify\n",
        "  the superclass by learning the right weights between the two models\n",
        "  in our case, this wil be a ResNet50 and Vit.\n",
        "\n",
        "  So each incoming feature vector will be a 3x1, and we will have two of them.\n",
        "  The output will be a 3x1 \n",
        "  softmax vector of the super classes \n",
        "  '''\n",
        "\n",
        "  def __init__(self, modelA, modelB):\n",
        "    super().__init__()\n",
        "    self.modelA = modelA\n",
        "    self.modelB = modelB\n",
        "    self.classifier = nn.Linear(2 * 3, 3)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    x1 = self.modelA(x)\n",
        "    x2 = self.modelB(x)\n",
        "    x = torch.cat((x1, x2), dim=1)\n",
        "    out = self.classifier(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "H4J9SCjiX0gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate large pre trained models and load our trained weights \n",
        "#initialize ensemble modles \n",
        "weights_resnet = torchvision.models.ResNet50_Weights.DEFAULT.DEFAULT\n",
        "resnet_model = torchvision.models.resnet50(weights=weights_resnet)\n",
        "in_ftrs = resnet_model.fc.in_features\n",
        "out_fts = 3\n",
        "resnet_model.fc = nn.Linear(in_ftrs, out_fts)\n",
        "resnet_model.load_state_dict(torch.load('/content/resnet_50.pth')) #whatever path holds the model ...this is what it was on my VM \n",
        "resnet_model.eval()\n",
        "\n",
        "resnet_model.to(device)\n",
        "\n",
        "\n",
        "weights_vit = torchvision.models.ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "\n",
        "vit_model = torchvision.models.vit_l_16(weights=weights_vit)\n",
        "vit_model.heads = torch.nn.Sequential( \n",
        "    torch.nn.Linear(in_features=1024, \n",
        "                    out_features=3,\n",
        "                    bias=True))\n",
        "vit_model.heads.load_state_dict(torch.load('/content/vit_l_16_classifier.pth'))#whatever path holds the model ...this is what it was on my VM \n",
        "vit_model.eval()\n",
        "\n",
        "vit_model.to(device)"
      ],
      "metadata": {
        "id": "gQck_L72YGrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate enesemble in eval mode\n",
        "ensemble_model_2 = EnsembleModelTwo(resnet_model, vit_model)\n",
        "\n",
        "\n",
        "PATH = '/content/ensemble__2_best.pth'\n",
        "\n",
        "\n",
        "\n",
        "# load in MY weights\n",
        "ensemble_model_2.classifier.load_state_dict(torch.load(PATH))\n",
        "ensemble_model_2.eval()\n"
      ],
      "metadata": {
        "id": "2D6vFf1qYh7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test ensemble \n",
        "# switch to cuda\n",
        "if torch.cuda.is_available():\n",
        "    ensemble_model_2.cuda()\n",
        "  \n",
        "\n",
        "# test_model(ensemble_model_2, test_dataloader, nn.CrossEntropyLoss(), device)\n"
      ],
      "metadata": {
        "id": "aa8brP9IYurK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UINvsvtLOxCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OOD Helpers\n",
        "\n",
        "# Generates 2048-dimensional feature embeddings from images\n",
        "def embed_images(model, dataloader):\n",
        "    feature_embeddings = []\n",
        "    for data in dataloader:\n",
        "        images, labels = data\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(images)\n",
        "            feature_embeddings.extend(embeddings.numpy())\n",
        "    feature_embeddings = np.array(feature_embeddings)\n",
        "    return feature_embeddings  # each row corresponds to embedding of a different image\n",
        "\n",
        "# Transform a single image\n",
        "def embed_single_image(model, image):\n",
        "    feature_embeddings = []\n",
        "    # image, labels = data\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(image)\n",
        "        feature_embeddings.extend(embeddings.detach().cpu().numpy())\n",
        "    feature_embeddings = np.array(feature_embeddings) # had to comment out here, since we switch to GPU \n",
        "    return feature_embeddings"
      ],
      "metadata": {
        "id": "OawRsyrgPD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OOD Instantiation\n",
        "\n",
        "# Load pretrained neural network\n",
        "ood_model = timm.create_model('resnet50', pretrained=True, num_classes=0)  # this is a pytorch network\n",
        "ood_model.eval()  # eval mode disables training-time operators (like batch normalization)\n",
        "if torch.cuda.is_available():\n",
        "    ood_model.cuda()\n",
        "\n",
        "# manual data transforms\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])\n",
        "\n",
        "#Create dataloaders for each superclass \n",
        "train_dog_dl, test_dog_dl, dog_classes = data_setup.create_dataloaders(\n",
        "                                                            train_dir=train_dog,\n",
        "                                                            test_dir=test_dog,\n",
        "                                                            transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                            batch_size=1) \n",
        "\n",
        "train_bird_dl, test_bird_dl, bird_classes = data_setup.create_dataloaders(\n",
        "                                                            train_dir=train_bird,\n",
        "                                                            test_dir=test_bird,\n",
        "                                                            transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                            batch_size=1) \n",
        "\n",
        "train_rep_dl, test_rep_dl, rep_classes = data_setup.create_dataloaders(\n",
        "                                                            train_dir=train_rep,\n",
        "                                                            test_dir=test_rep,\n",
        "                                                            transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                            batch_size=1) \n",
        "\n",
        "\n",
        "\n",
        "# generate ood predictions for every image in testing example\n",
        "\n",
        "## gather training embeddings for each super class\n",
        "train_feature_embeddings_dog = embed_images(ood_model, train_dog_dl)\n",
        "train_feature_embeddings_bird = embed_images(ood_model, train_bird_dl)\n",
        "train_feature_embeddings_rep = embed_images(ood_model, train_rep_dl)\n",
        "\n",
        "## fit scores to training for each super class embeddings\n",
        "# dog\n",
        "dog_ood = OutOfDistribution()\n",
        "train_ood_features_scores_dog = dog_ood.fit_score(features=train_feature_embeddings_dog)\n",
        "# bird\n",
        "bird_ood = OutOfDistribution()\n",
        "train_ood_features_scores_bird = bird_ood.fit_score(features=train_feature_embeddings_bird)\n",
        "# reptile\n",
        "rep_ood = OutOfDistribution()\n",
        "train_ood_features_scores_rep = rep_ood.fit_score(features=train_feature_embeddings_rep)\n",
        "\n",
        "\n",
        "# delete to clear up RAM\n",
        "del train_feature_embeddings_dog, train_feature_embeddings_bird, train_feature_embeddings_rep\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "rwH0hkouO2a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SubClass Model Instantiation\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.ResNet50_Weights.DEFAULT.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "\n",
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "\n",
        "#Create dataloaders for each superclass \n",
        "resnet_train_dog_dl, resnet_test_dog_dl, resnet_dog_classes = data_setup.create_dataloaders(\n",
        "                                                                        train_dir=train_dog,\n",
        "                                                                        test_dir=test_dog,\n",
        "                                                                        transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                                        batch_size=batch_size) \n",
        "\n",
        "resnet_train_bird_dl, resnet_test_bird_dl, resnet_bird_classes = data_setup.create_dataloaders(\n",
        "                                                                        train_dir=train_bird,\n",
        "                                                                        test_dir=test_bird,\n",
        "                                                                        transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                                        batch_size=batch_size) \n",
        "\n",
        "resnet_train_rep_dl, resnet_test_rep_dl, resnet_rep_classes = data_setup.create_dataloaders(\n",
        "                                                                        train_dir=train_rep,\n",
        "                                                                        test_dir=test_rep,\n",
        "                                                                        transform=manual_transforms,#use manual transforms so its the same in ensemble\n",
        "                                                                        batch_size=batch_size)\n",
        "\n",
        "### DOG MODEL ###\n",
        "# Instantiate Dog Model\n",
        "dog_model = torchvision.models.resnet50()\n",
        "\n",
        "\n",
        "# configure output\n",
        "in_ftrs = dog_model.fc.in_features\n",
        "out_fts = len(resnet_dog_classes)\n",
        "dog_model.fc = nn.Linear(in_ftrs, out_fts)\n",
        "\n",
        "# load in MY weights\n",
        "dog_model.load_state_dict(torch.load('/content/DOG_resnet.pth'))\n",
        "dog_model.eval()\n",
        "\n",
        "# switch to cuda\n",
        "if torch.cuda.is_available():\n",
        "    dog_model.cuda()\n",
        "\n",
        "\n",
        "### BIRD MODEL ###\n",
        "# Instantiate BIRD Model\n",
        "bird_model = torchvision.models.resnet50()\n",
        "\n",
        "# configure output\n",
        "in_ftrs = bird_model.fc.in_features\n",
        "out_fts = len(resnet_bird_classes)\n",
        "bird_model.fc = nn.Linear(in_ftrs, out_fts)\n",
        "\n",
        "# load in MY weights\n",
        "bird_model.load_state_dict(torch.load('/content/BIRD_resnet.pth'))\n",
        "bird_model.eval()\n",
        "\n",
        "# switch to cuda\n",
        "if torch.cuda.is_available():\n",
        "    bird_model.cuda()\n",
        "\n",
        "\n",
        "### REPTILE MODEL ###\n",
        "# Instantiate BIRD Model\n",
        "rep_model = torchvision.models.resnet50()\n",
        "\n",
        "# configure output\n",
        "in_ftrs = rep_model.fc.in_features\n",
        "out_fts = len(resnet_rep_classes)\n",
        "rep_model.fc = nn.Linear(in_ftrs, out_fts)\n",
        "\n",
        "# load in MY weights\n",
        "rep_model.load_state_dict(torch.load('/content/REP_resnet.pth'))\n",
        "rep_model.eval()\n",
        "\n",
        "# switch to cuda\n",
        "if torch.cuda.is_available():\n",
        "    rep_model.cuda()\n",
        "\n"
      ],
      "metadata": {
        "id": "loVc49ZVQZYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-K7l2PJXndu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8jJ_wF3XnXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/neuralnet_competition_data-repository:latest')\n",
        "\n",
        "# Extract images\n",
        "# !unzip \"neuralnet_competition_data/X_train.zip\"\n",
        "# !unzip \"neuralnet_competition_data/X_test.zip\" \n",
        "\n",
        "# LOAD-IN Competition Data !!!\n",
        "\n",
        "# Create ordered list of filepaths \n",
        "test_filepaths = [('/content/test_shuffle/' + str(i) + '.jpg') for i in range(0, 9127)]\n",
        "\n",
        "\n",
        "def preprocessor(image_filepath, transform):\n",
        "        image = torchvision.io.read_image(image_filepath)\n",
        "        transformed = transform(image)\n",
        "        X = torch.reshape(transformed, (1, 3, 224, 224))\n",
        "        return X.to(device).float()\n",
        "\n",
        "\n",
        "# pre-process Testing Data\n",
        "X_test = [preprocessor(x, T.Resize((224,224))) for x in test_filepaths]\n"
      ],
      "metadata": {
        "id": "brE0lBE50RpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zmsVwP-YFJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BURl43E4YFEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Put it all together!\n",
        "\n",
        "'''\n",
        "First, it would most likely be beneficial to have batch_size = 1, so we basically loop thru one example at a time,\n",
        "classify it as [bird, reptile, dog], check if sample is likely to be OOD, and if not, feed into pre-specified subclassifier\n",
        "'''\n",
        "\n",
        "\n",
        "# instantiate ensemble mode\n",
        "model = ensemble_model_2\n",
        "\n",
        "# threshold for OOD\n",
        "threshold = 0.5 # up for discussion obv\n",
        "\n",
        "# loop thru and predict\n",
        "superclasses = []\n",
        "subclasses = []\n",
        "with torch.inference_mode():\n",
        "    for image in X_test:\n",
        "\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(image)\n",
        "\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        label = train_dataloader.dataset.classes[predicted] # this var is [dog, reptile, bird]\n",
        "        superclasses.append(label)\n",
        "\n",
        "        #create the embedding for the test image\n",
        "        test_feature_embeddings = embed_single_image(ood_model, image)\n",
        "\n",
        "        #based on the label (dog, bird, rep), we need use the corresponding embeddings to create a feature scores\n",
        "        if label == 'bird': #MAKE SURE TEST_OOD_FEATURES_SCORE IS A NUMPY ARRAY WITH ONE ELEMENT\n",
        "            test_ood_features_score = bird_ood.score(features=test_feature_embeddings)\n",
        "        elif label == 'dog':\n",
        "            test_ood_features_score = dog_ood.score(features=test_feature_embeddings)\n",
        "        else:\n",
        "            test_ood_features_score = rep_ood.score(features=test_feature_embeddings)\n",
        "\n",
        "        # yup, test_odd_features_score is an array\n",
        "        if test_ood_features_score[0] < threshold:\n",
        "            subclass = 'novel'\n",
        "        else:\n",
        "            if label == 'dog':\n",
        "                pred = dog_model(image)\n",
        "                _, predicted = torch.max(pred.data, 1)\n",
        "                subclass = resnet_test_dog_dl.dataset.classes[predicted]\n",
        "\n",
        "            elif label == 'reptile':\n",
        "                pred = rep_model(image)\n",
        "                _, predicted = torch.max(pred.data, 1)\n",
        "                subclass = resnet_test_rep_dl.dataset.classes[predicted]\n",
        "\n",
        "            else:\n",
        "                pred = bird_model(image)\n",
        "                _, predicted = torch.max(pred.data, 1)\n",
        "                subclass = resnet_test_bird_dl.dataset.classes[predicted]\n",
        "        # append\n",
        "        subclasses.append(subclass)\n"
      ],
      "metadata": {
        "id": "H5yfuCp5QJVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LA0D-xRr3RcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUhWiyQX3RSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preds(superclasses, subclasses):\n",
        "    super_preds, sub_preds = pd.read_csv('/content/predictions_sample.csv'), pd.read_csv('/content/predictions_sample.csv')\n",
        "    super_preds['predictions'] = superclasses\n",
        "    sub_preds['predictions'] = subclasses\n",
        "    return super_preds, sub_preds\n",
        "\n",
        "\n",
        "# convert & export\n",
        "super_preds, sub_preds = create_preds(superclasses, subclasses)\n",
        "super_preds.to_csv('/content/SUPER_preds.csv')\n",
        "sub_preds.to_csv('/content/SUB_preds.csv')"
      ],
      "metadata": {
        "id": "1Mz3Ep8z3RKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNhKrDdl2myW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsKg_mZJ2mvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, SUBMIT !!\n",
        "import aimodelshare as ai\n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "\n",
        "# Superclass Submission\n",
        "SUPER_apiurl = \"https://8vhobca1n7.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
        "set_credentials(apiurl=SUPER_apiurl)\n",
        "\n",
        "#Instantiate Competition\n",
        "mycompetition= ai.Competition(SUPER_apiurl)\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                                 preprocessor_filepath=None,\n",
        "                                 prediction_submission=superclasses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLOIFQgZkBAo",
        "outputId": "d31921e4-0b4f-441f-9471-c9e0500f88e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n",
            "Insert search tags to help users find your model (optional): ResNet/ViT Ensemble\n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 193\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclass Submission\n",
        "\n",
        "SUB_apiurl= \"https://arj1w1ffm6.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
        "set_credentials(apiurl=SUB_apiurl)\n",
        "\n",
        "#Instantiate Competition\n",
        "mycompetition= ai.Competition(SUB_apiurl)\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = None,\n",
        "                                 preprocessor_filepath=None,\n",
        "                                 prediction_submission=subclasses)"
      ],
      "metadata": {
        "id": "jdGWfhiiR_wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZJD7LMxGBl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88LvefEyGBfA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}